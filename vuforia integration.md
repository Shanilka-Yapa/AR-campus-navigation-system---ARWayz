AR Wayz: Functional Documentation
1. System Overview
AR Wayz is an indoor navigation application designed to guide users through complex environments (such as university campuses or large buildings) using Augmented Reality (AR). Unlike traditional GPS navigation, which struggles indoors, AR Wayz utilizes computer vision to overlay directional arrows directly onto the real-world camera feed, providing an intuitive "follow-the-line" experience.

The application operates on a hybrid architecture:

Flutter: Manages the 2D user interface (menus, destination selection, settings).

Unity + Vuforia: Handles the 3D AR processing, environment tracking, and pathfinding physics.

2. Core Functionalities
2.1. Environment Recognition & Tracking (The "Eyes")
The core of the AR experience is powered by Vuforia Engine.

Functionality: When the user opens the AR camera, the app analyzes the video feed to recognize the user's physical location.

Technology Used: The app utilizes Vuforia Area Targets (or Image Targets/Model Targets depending on your specific setup).

Area Targets: The app compares the live camera feed against a pre-scanned 3D digital twin of the building. This allows the device to understand exactly where it is and which direction it is facing with centimeter-level accuracy.

Synchronization: Once the location is locked, the virtual camera in Unity is synchronized with the physical camera on the phone.

2.2. Intelligent Pathfinding (The "Brain")
Once the user's location is known, the app calculates the best route to their chosen destination.

Functionality: Users select a destination (e.g., "Library") in the Flutter UI. This destination is sent to the Unity backend.

Technology Used: Unity NavMesh (Navigation Mesh).

The building's floor plan is baked into a "NavMesh," which defines walkable surfaces and obstacles (walls, furniture).

The app uses Dijkstraâ€™s algorithm (via Unity's NavMeshAgent) to calculate the shortest path from the user's current coordinates to the destination coordinates.

This path is dynamic; if the user deviates, the path can be recalculated instantly.

2.3. Augmented Reality Visualization (The "Guide")
The calculated path is visualized as 3D objects overlaid on the real world.

Functionality: Instead of a 2D map, the user sees a series of 3D directional arrows floating on the floor.

Technology Used: Unity 3D Rendering.

The app draws a LineRenderer or instantiates 3D Arrow Prefabs along the path points generated by the NavMesh.

As the user walks, the arrows remain "anchored" to the physical floor, creating the illusion that they are painted on the ground.

The arrows update in real-time as the user moves closer to the destination.

2.4. Hybrid Interface Communication (The "Bridge")
The app seamlessly integrates standard mobile app features with high-performance 3D graphics.

Functionality: The user interacts with standard buttons and text inputs in Flutter, but views the AR content in a specialized window.

Technology Used: Flutter Unity Widget.

A bidirectional communication bridge connects the two layers.

Flutter to Unity: Sends commands like "Start Navigation to Room 304".

Unity to Flutter: Sends status updates like "Arrived at Destination" or "Lost Tracking," which Flutter then displays as pop-up notifications or UI alerts.

3. User Journey (Workflow)
Initialization: The user launches the app and grants camera permissions. The Flutter UI loads.

Destination Selection: The user selects a location from a list or search bar in the Flutter interface.

AR Mode Activation: The app switches to the camera view (Unity view).

Localization: The user points the camera at their surroundings. Vuforia recognizes features in the environment and establishes the device's position.

Path Generation: A trail of AR arrows appears on the screen, originating from the user's feet and leading toward the destination.

Navigation: The user walks following the arrows. The path updates as they move.

Arrival: Upon reaching the destination, a "You have arrived" message is triggered by Unity and displayed by the Flutter UI.

4. Technical Constraints & Requirements
Lighting: The functionality relies on the camera's ability to see environment details; therefore, the app requires moderate to bright lighting conditions.

Device Sensors: Requires a device with a working gyroscope and accelerometer for stable AR tracking.

Space Scanning: The environment must be pre-scanned or mapped for Vuforia to recognize it.
